{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJOhAF-qnZJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31fbc000-cf21-4e4f-8c98-926cff702526"
      },
      "source": [
        "!pip install Unidecode"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p67DKhxYnbuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import minmax_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIFfkjzYnbpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "da40fb71-19a2-452c-e88a-798d19b5f476"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5M8lubNTPO-",
        "colab_type": "code",
        "outputId": "e3f34274-d235-481b-f989-43db70a92530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_-pMytunblo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset from metadata file\n",
        "file=open(\"/content/drive/My Drive/ML project'20/YelpZip/metadata\")\n",
        "data=file.readlines()\n",
        "file.close()\n",
        "for ind in range(len(data)):\n",
        "    data[ind]=data[ind].split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zuFmI5QnbjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load reviews from reviewcontent file\n",
        "file2=open(\"/content/drive/My Drive/ML project'20/YelpZip/reviewContent\")\n",
        "text=file2.readlines()\n",
        "file2.close()\n",
        "for i in range(len(text)):\n",
        "    text[i]=text[i].split(\"\\t\")\n",
        "text=[t[3] for t in text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBNFN3NEnbgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dataset=pd.DataFrame(data,columns=[\"user_id\",'product_id','rating','label','date'])\n",
        "Dataset[\"review_text\"]=text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYZE0jnxnbd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('mode.chained_assignment', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOE2g5WonsNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dataset['rating']=Dataset['rating'].astype('float')\n",
        "Dataset['date']=pd.to_datetime(Dataset['date'])\n",
        "Dataset['day']=Dataset['date'].dt.day_name()\n",
        "Dataset['year']=Dataset.date.dt.year\n",
        "Dataset['label']=Dataset.label.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en0fWiT7nsLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cf5725bd-6ed6-4dc8-cc6f-a6193f7fb76a"
      },
      "source": [
        "Y={}\n",
        "for y in Dataset.year:\n",
        "  if y in Y:\n",
        "    Y[y]+=1\n",
        "  else:\n",
        "    Y[y]=0\n",
        "Y"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2004: 2,\n",
              " 2005: 426,\n",
              " 2006: 2261,\n",
              " 2007: 7535,\n",
              " 2008: 16781,\n",
              " 2009: 31907,\n",
              " 2010: 54578,\n",
              " 2011: 80212,\n",
              " 2012: 97961,\n",
              " 2013: 131225,\n",
              " 2014: 180674,\n",
              " 2015: 5024}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PmHakPtnsIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84ee7db5-92a3-4a33-f2b9-4e9edcadc08e"
      },
      "source": [
        "x=Dataset[Dataset.year== 2012]\n",
        "x=x.append(Dataset[Dataset.year==2013])\n",
        "x=x.append(Dataset[Dataset.year==2014])\n",
        "train_data=x.sample(n=25000)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(409863, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xkzdrA3qSBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eddca0d6-512c-4d31-e1da-295cc3d889d3"
      },
      "source": [
        "test_data=Dataset[Dataset.year==2015]\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 8)\n",
            "(5025, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGszfoioonYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4fd376e9-6c32-4cd2-a580-59a8542b809e"
      },
      "source": [
        "# X_train['upper_case_word_count']=X_train['review_text'].apply(lambda x:len([y for y in x.split() if y) )\n",
        "#Train Dataset\n",
        "#Review centric features\n",
        "train_data['word_count']=train_data['review_text'].apply(lambda x: len(x.split()))\n",
        "train_data['punctuation_count']=train_data['review_text'].apply(lambda x: len(''.join(c for c in x if c in string.punctuation)))\n",
        "train_data['char_count']=train_data['review_text'].apply(lambda x: len(x))\n",
        "train_data['title_count']=train_data['review_text'].apply(lambda x: len([word for word in x.split() if word.istitle()]))\n",
        "print(\"-----------review_centric features extracted-------------/\")\n",
        "# user-centric features\n",
        "train_data['user_id_no_of_review'] = train_data.groupby('user_id')['user_id'].transform('size')\n",
        "train_data['user_id_ave_rating'] = train_data.groupby('user_id')['rating'].transform('mean')\n",
        "train_data['user_id_ave_no_words'] = train_data.groupby('user_id')['word_count'].transform('mean')\n",
        "train_data['user_id_max_review_a_day'] = train_data.groupby(['user_id','day'])['user_id'].transform('size')\n",
        "print(\"-----------user_centric features extracted-------------/\")\n",
        "#Product centric feature\n",
        "train_data['product_id_no_of_review']=train_data.groupby('product_id')['product_id'].transform('size')\n",
        "train_data['product_id_ave_rating']=train_data.groupby('product_id')['rating'].transform('mean')\n",
        "train_data['product_id_ave_no_of_words']=train_data.groupby('product_id')['word_count'].transform('mean')\n",
        "train_data['product_id_max_review_a_day']=train_data.groupby(['product_id','day'])['user_id'].transform('size')\n",
        "print(\"-----------product_centric features extracted-------------/\\n\\n\")\n",
        "\n",
        "#Test dataset\n",
        "test_data['word_count']=test_data['review_text'].apply(lambda x: len(x.split()))\n",
        "test_data['punctuation_count']=test_data['review_text'].apply(lambda x: len(''.join(c for c in x if c in string.punctuation)))\n",
        "test_data['char_count']=test_data['review_text'].apply(lambda x: len(x))\n",
        "test_data['title_count']=test_data['review_text'].apply(lambda x: len([word for word in x.split() if word.istitle()]))\n",
        "print(\"-----------review_centric features extracted-------------/\")\n",
        "# user-centric features\n",
        "test_data['user_id_no_of_review'] = test_data.groupby('user_id')['user_id'].transform('size')\n",
        "test_data['user_id_ave_rating'] = test_data.groupby('user_id')['rating'].transform('mean')\n",
        "test_data['user_id_ave_no_words'] = test_data.groupby('user_id')['word_count'].transform('mean')\n",
        "test_data['user_id_max_review_a_day'] = test_data.groupby(['user_id','day'])['user_id'].transform('size')\n",
        "print(\"-----------user_centric features extracted-------------/\")\n",
        "#Product centric feature\n",
        "test_data['product_id_no_of_review']=test_data.groupby('product_id')['product_id'].transform('size')\n",
        "test_data['product_id_ave_rating']=test_data.groupby('product_id')['rating'].transform('mean')\n",
        "test_data['product_id_ave_no_of_words']=test_data.groupby('product_id')['word_count'].transform('mean')\n",
        "test_data['product_id_max_review_a_day']=test_data.groupby(['product_id','day'])['user_id'].transform('size')\n",
        "print(\"-----------product_centric features extracted-------------/\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------review_centric features extracted-------------/\n",
            "-----------user_centric features extracted-------------/\n",
            "-----------product_centric features extracted-------------/\n",
            "\n",
            "\n",
            "-----------review_centric features extracted-------------/\n",
            "-----------user_centric features extracted-------------/\n",
            "-----------product_centric features extracted-------------/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeKYiYwLpL_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "d884e2da-3f0f-4c77-9aa6-ae11843ffe4b"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>date</th>\n",
              "      <th>review_text</th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>word_count</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>title_count</th>\n",
              "      <th>user_id_no_of_review</th>\n",
              "      <th>user_id_ave_rating</th>\n",
              "      <th>user_id_ave_no_words</th>\n",
              "      <th>user_id_max_review_a_day</th>\n",
              "      <th>product_id_no_of_review</th>\n",
              "      <th>product_id_ave_rating</th>\n",
              "      <th>product_id_ave_no_of_words</th>\n",
              "      <th>product_id_max_review_a_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112040</th>\n",
              "      <td>61337</td>\n",
              "      <td>1006</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-10-24</td>\n",
              "      <td>It's very rare for me to give a place 5 stars,...</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>2013</td>\n",
              "      <td>244</td>\n",
              "      <td>35</td>\n",
              "      <td>1344</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>263.0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.352941</td>\n",
              "      <td>161.176471</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118283</th>\n",
              "      <td>84141</td>\n",
              "      <td>1050</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-08-17</td>\n",
              "      <td>Two words: Pork Belly!  I would come back just...</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2014</td>\n",
              "      <td>145</td>\n",
              "      <td>22</td>\n",
              "      <td>826</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>3.466667</td>\n",
              "      <td>150.200000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479516</th>\n",
              "      <td>226573</td>\n",
              "      <td>3964</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-12-03</td>\n",
              "      <td>Went for a holiday meal with the family. Good ...</td>\n",
              "      <td>Monday</td>\n",
              "      <td>2012</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>130.500000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103566</th>\n",
              "      <td>76102</td>\n",
              "      <td>2669</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-09-10</td>\n",
              "      <td>Selection was mediocre.  My steak was cooked p...</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>2014</td>\n",
              "      <td>102</td>\n",
              "      <td>15</td>\n",
              "      <td>611</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100113</th>\n",
              "      <td>35307</td>\n",
              "      <td>914</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-12-22</td>\n",
              "      <td>Had the lamb curry platter and my wife had the...</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>2012</td>\n",
              "      <td>36</td>\n",
              "      <td>8</td>\n",
              "      <td>202</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_id  ... product_id_max_review_a_day\n",
              "112040   61337  ...                           4\n",
              "118283   84141  ...                           4\n",
              "479516  226573  ...                           3\n",
              "103566   76102  ...                           1\n",
              "100113   35307  ...                           1\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBmj2YwqpO87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.to_csv(\"/content/drive/My Drive/ML project'20/YelpZip/train.csv\")\n",
        "test_data.to_csv(\"/content/drive/My Drive/ML project'20/YelpZip/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}